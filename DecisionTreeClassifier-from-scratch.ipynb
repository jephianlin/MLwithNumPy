{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "**Input:**  \n",
    "- `X`: an array of shape `(N,d)` whose rows are samples and columns are features\n",
    "- `y`: the labels of shape `(N,)`\n",
    "- `criterion`: `\"gini\"` or `\"entropy\"`  \n",
    "\n",
    "**Output:**  \n",
    "A tuple `(predict, tree)`.  \n",
    "- `predict`: a function that takes data `X_sample` and output their predicted labels\n",
    "- `tree`: a dictionary that contains the information same as those in `model.tree_`\n",
    "\n",
    "**Steps:**\n",
    "1. Define $\\operatorname{node}({\\bf x}) = 0$ for every sample point ${\\bf x}$.  \n",
    "2. Let `queue = [0]` and `node_count = 0` .\n",
    "3. While `queue` is not empty:  \n",
    "    1. Pick the first element $k$ from `queue` and remove it.\n",
    "    2. Let $U$ be the points with $\\operatorname{node}({\\bf x}) = k$.\n",
    "    3. Compute $\\operatorname{imp}(k)$ as the impurity of labels of $U$.  \n",
    "If $\\operatorname{imp}(k)=0$, then skip this loop.\n",
    "    4. For each feature $f_j$ and each sample point ${\\bf x}_i\\in U$, partition $U$ into two parts $L$ and $R$ by the criteria $f_j({\\bf x}) \\leq f_j({\\bf x}_i)$, calculate the impurity $H_L$ and $H_R$ in each part, and obtain the value  \n",
    "$$I'_{j,i} = \\frac{|L|}{|U|}H_L + \\frac{|R|}{|U|}H_R.$$\n",
    "    5. Pick a pair $j$ and $i$ that achieves the minimum $I'_{j,i}$.  \n",
    "Let $\\operatorname{node}({\\bf x})$ be `node_count+1` if ${\\bf x}\\in L$.  \n",
    "Let $\\operatorname{node}({\\bf x})$ be `node_count+2` if ${\\bf x}\\in R$.  \n",
    "Let `queue += [node_count+1, node_count+2]` and `node_count += 2` .\n",
    "\n",
    "4. Each new point falls into a unique leaf in your decision tree.  Since each leaf contains only one class, use the class as the prediction of this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode\n",
    "Translate the algorithm into the pseudocode.  \n",
    "This helps you to identify the parts that you don't know how to do it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. \n",
    "    2. \n",
    "    3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Take some sample data from [DecisionTreeClassifier-with-scikit-learn](DecisionTreeClassifier-with-scikit-learn.ipynb) and check if your code generates similar outputs with the existing packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Name of the data\n",
    "Description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### results with your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### results with existing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "t = np.arange(20)\n",
    "angle = 2 * np.pi / 20 * t\n",
    "X1 = np.vstack([np.cos(angle), np.sin(angle)]).T\n",
    "X2 = 5 * X1\n",
    "X = np.vstack([X1, X2])\n",
    "X_sample = 10 * np.random.rand(1000,2) - np.array([5,5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Train a decision tree classification model by `X` and `y` .  \n",
    "Make a prediction of `X_sample` by:  \n",
    "1. your code with different algorithm settings\n",
    "2. `sklearn.neighbors.KNeighborsClassifier`\n",
    "\n",
    "The results should be the same (or almost the same).  \n",
    "Check if this is true.  \n",
    "(Note: the uncertainty is caused by the choice of cut when there are several cuts with the same information gain.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Let `y_new` be the prediction of `X_sample` in the previous question. \n",
    "Plot the points (rows) in `X` with `c=y` .  \n",
    "Plot the points (rows) in `X_sample` with `c=y_new` and `alpha=0.1` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Let  \n",
    "```python\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "```  \n",
    "The corresponding values in `model.tree_` and those in your `tree` should be almost the same.  \n",
    "Check if this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "m,n = 8,8\n",
    "frames = (m-2) * (n-2)\n",
    "\n",
    "o = np.array([[1,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "x = np.array([[1,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "oo = np.zeros((frames, m, n))\n",
    "xx = np.zeros((frames, m, n))\n",
    "count =  0\n",
    "for i in range(m-2):\n",
    "    for j in range(n-2):\n",
    "        oo[count, i:i+3, j:j+3] = o\n",
    "        xx[count, i:i+3, j:j+3] = x\n",
    "        count += 1\n",
    "\n",
    "\n",
    "X = np.vstack([oo, xx]).reshape(2*frames, -1)\n",
    "y = np.array([0]*frames + [1]*frames)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Train a decision tree classification model by `X` an `y` .  \n",
    "Make a prediction `y_new` for the training data `X` .  \n",
    "What is the outcome?  \n",
    "Can we say decision tree model is better than the $k$-nearest neighbors model?  (open answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "Print the `n_node_samples` for each leaf.  \n",
    "Does the leaves contain many samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(c)\n",
    "What is the depth of the decision tree?  \n",
    "(The depth of a tree is the number of vertices on the longest path from a root to a leaf.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
