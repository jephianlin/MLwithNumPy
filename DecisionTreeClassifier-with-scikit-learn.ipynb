{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier with scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creative Commons License](https://i.creativecommons.org/l/by/4.0/88x31.png)  \n",
    "This work by Jephian Lin is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(<parameters)\n",
    "model.fit(X, y)\n",
    "y_new = model.predict(X_test)\n",
    "```\n",
    "\n",
    "[Official Reference](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- `criterion`: `\"gini\"` or `\"entropy\"`  \n",
    "the function to measure a good cut\n",
    "- `max_depth`: an integer, the maximum depth of a tree\n",
    "- `min_samples_split`: if a node has more than `min_samples_split` samples, then split further\n",
    "\n",
    "and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "- `classes_`: an array of shape `(n_classes,)`  \n",
    "(Usually `0, ..., n_classes-1`)\n",
    "- `feature_importances_`: an array of shape `(n_features,)`  \n",
    "the total importance (impurity reduction) of each feature\n",
    "- `tree_`: the constructed decition tree\n",
    "\n",
    "For `model.tree_`  \n",
    "- `children_left[i]`: id of the left child of node i or -1 if leaf node\n",
    "- `children_right[i]`: id of the right child of node i or -1 if leaf node\n",
    "- `feature[i]`: feature used for splitting node i\n",
    "- `threshold[i]`: threshold value at node i\n",
    "- `n_node_samples[i]`: the number of of training samples reaching node i\n",
    "- `impurity[i]`: the impurity at node i\n",
    "\n",
    "(Source: [Understanding the decision tree structure](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1\n",
    "Let  \n",
    "```python\n",
    "mu1 = np.array([1,1])\n",
    "cov1 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "mu2 = np.array([-1,-1])\n",
    "cov2 = np.array([[1.1,-1],\n",
    "                [-1,1.1]])\n",
    "X = np.vstack([np.random.multivariate_normal(mu1, cov1, 100), \n",
    "               np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "y = np.array([0]*100 + [1]*100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(a)\n",
    "Plot the points (rows) in `X` with `c=y` .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(b)\n",
    "Draw 1000 random points uniformly on the region $-5\\leq x\\leq 5$ and $-5\\leq y\\leq 5$.  \n",
    "Use the trained model to make a prediction `y_new` .  \n",
    "Then plot these 1000 points with `c=y_new` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1(c)\n",
    "Trains a decision tree model.  \n",
    "Let  \n",
    "```python\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(model)\n",
    "```\n",
    "Try to understand the following questions:\n",
    "- Check if the number of samples in a node is equal to the sum of those in its two children\n",
    "- What can you say about the `gini` value at each leaf node?\n",
    "- What can you say about the `value` distribution at each leaf node?\n",
    "- Check how many samples satisfies the criteria at the root node.  It should be the same as the number of samples in the left child (of the root)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2\n",
    "Let  \n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(a)\n",
    "Apply the decision tree classification algorithm to `X` and `y` .  \n",
    "Make a prediciont of the training data.  \n",
    "How is the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(b)\n",
    "Plot the decision tree.  \n",
    "If a bag of $n$ balls contains $n_i$ balls of color $i$ (for colors $i=0,\\ldots,c-1$), the **Gini impurity** of this bag (distribution) is  \n",
    "$$\\sum_{i=0}^{c-1} p_i(1 - p_i),$$\n",
    "where $p_i = n_i/n$ is the probability of getting a ball of color $i$.\n",
    "\n",
    "Pick a node and check if this formula is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2(c)\n",
    "Change the model setting to `criteria=\"entropy\"` and plot the decision tree again.  \n",
    "If a bag of $n$ balls contains $n_i$ balls of color $i$ (for colors $i=0,\\ldots,c-1$), the **entropy** of this bag (distribution) is  \n",
    "$$\\sum_{i=0}^{c-1} -p_i\\log_2(p_i),$$\n",
    "where $p_i = n_i/n$ is the probability of getting a ball of color $i$.\n",
    "\n",
    "Pick a node and check if this formula is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 3\n",
    "Let  \n",
    "```python\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "mask = (digits.target == 0) | (digits.target == 1)\n",
    "X = digits.data[mask]\n",
    "y = digits.target[mask]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(a)\n",
    "Train a decision tree classification model.  \n",
    "How is its accuracy score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3(b)\n",
    "Use any software or online app to draw a picture of 0 or 1.  \n",
    "Save it as a file, e.g., `my_digit.png` .  \n",
    "Use the following code to load it.  \n",
    "```python\n",
    "from PIL import Image\n",
    "img = Image.open(\"my_digit.png\").resize(8,8)\n",
    "```\n",
    "Does the model give you the right answer?  \n",
    "Each of you can do 5 pictures.  \n",
    "Let's see what is the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 4\n",
    "Let  \n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "```  \n",
    "and `model` be your decision tree classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(a)\n",
    "Plot the decision tree with the keyword `node_ids=True` .  \n",
    "(If necessary, you may use `plt.figure(figsize=(15,15))` to change the figure size.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(b)\n",
    "Let `T = model.tree_` .  \n",
    "Print `T.children_left` and `T.children_right` .  \n",
    "Compare these two arrays with the decision tree you printed.  \n",
    "What do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(c)\n",
    "Print `T.feature` and `T.threshold` .  \n",
    "Compare these two arrays with the decision tree you printed.  \n",
    "What do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(d)\n",
    "Print `T.n_node_samples` and `T.impurity` .  \n",
    "Compare these two arrays with the decision tree you printed.  \n",
    "What do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(e)\n",
    "For each `i = 0,1,2,3`, count how many nodes uses feature `i` for splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(f)\n",
    "Suppose there are $N$ sample points in the training data.  \n",
    "Suppose a node contains $n_s$ sample points.  \n",
    "Within these sample points, there is a chance of $p_i$ to get class $i$.  \n",
    "One may calculate the impurity $H$ (Gini or entropy) at this point.  \n",
    "\n",
    "Suppose the \"information\" at each node is  \n",
    "$$I = \\frac{n_s}{N}\\cdot H.$$\n",
    "Calculate the information at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(e)\n",
    "Suppose $I$ is the information at one node, while $I_\\ell$ and $I_r$ are the information at its left and right children, respectively.  \n",
    "The **information gain** at this node is $I_\\ell + I_r -I$.  \n",
    "Calculate the information gain at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4(f)\n",
    "Let $W_i$ be the sum of information gain among nodes using feature $i$ for splitting.  \n",
    "Calculate an array `W` such whose entries are `W_i` for each feature $i$.  \n",
    "Let `W = W / W.sum()` .  \n",
    "Compare `W` with `model.feature_importances_` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5\n",
    "Let  \n",
    "```python \n",
    "X = 5 * np.random.randn(1000,2)\n",
    "lengths = np.linalg.norm(X, axis=1)\n",
    "band1 = (lengths > 1) & (lengths <2)  \n",
    "band2 = (lengths > 3) & (lengths <4)  \n",
    "X = X[band1 | band2, :]\n",
    "y = np.array([0]*band1.shape[0] + [1]*band2.shape[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5(a)\n",
    "Go through the split-train-test process.  \n",
    "What is the accuracy score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5(b)\n",
    "Use some random points to plot the regions for each class.  \n",
    "(Just as what we did in Exercise 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
